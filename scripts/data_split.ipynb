{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca07c92a6f64a74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T07:20:29.367299Z",
     "start_time": "2025-03-08T07:20:29.207419Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "dataset_path = Path(\".\")\n",
    "labels = sorted(dataset_path.rglob(\"*labels/*.txt\"))  # all data in 'labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0801eb410619f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T07:20:29.968697Z",
     "start_time": "2025-03-08T07:20:29.952694Z"
    }
   },
   "outputs": [],
   "source": [
    "yaml_file = \"timmies.yaml\"  # your data YAML with data directories and names dictionary\n",
    "with open(yaml_file, \"r\", encoding=\"utf8\") as y:\n",
    "    classes = yaml.safe_load(y)[\"names\"]\n",
    "cls_idx = sorted(classes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a03bb9f1db1ef2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T07:20:30.969003Z",
     "start_time": "2025-03-08T07:20:30.387695Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "index = [label.stem for label in labels]  # uses base filename as ID (no extension)\n",
    "labels_df = pd.DataFrame([], columns=cls_idx, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b99c94bebbd506",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T07:20:51.084471Z",
     "start_time": "2025-03-08T07:20:31.599663Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "for label in labels:\n",
    "    lbl_counter = Counter()\n",
    "\n",
    "    with open(label, \"r\") as lf:\n",
    "        lines = lf.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        # classes for YOLO label uses integer at first position of each line\n",
    "        lbl_counter[int(line.split(\" \")[0])] += 1\n",
    "\n",
    "    labels_df.loc[label.stem] = lbl_counter\n",
    "\n",
    "labels_df = labels_df.fillna(0.0)  # replace `nan` values with `0.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3628ac18a8754f42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T07:20:51.115084Z",
     "start_time": "2025-03-08T07:20:51.085471Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9ae61d161905e1",
   "metadata": {},
   "source": [
    "K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb2649aea8242ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T07:20:52.119868Z",
     "start_time": "2025-03-08T07:20:51.116081Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "ksplit = 2\n",
    "kf = KFold(n_splits=ksplit, shuffle=True, random_state=20)  # setting random_state for repeatable results\n",
    "\n",
    "kfolds = list(kf.split(labels_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1293699c7511d9be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T07:20:52.147867Z",
     "start_time": "2025-03-08T07:20:52.122874Z"
    }
   },
   "outputs": [],
   "source": [
    "folds = [f\"split_{n}\" for n in range(1, ksplit + 1)]\n",
    "folds_df = pd.DataFrame(index=index, columns=folds)\n",
    "\n",
    "for i, (train, val) in enumerate(kfolds, start=1):\n",
    "    folds_df[f\"split_{i}\"].loc[labels_df.iloc[train].index] = \"train\"\n",
    "    folds_df[f\"split_{i}\"].loc[labels_df.iloc[val].index] = \"val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d603367dc7ecab49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T07:20:52.163867Z",
     "start_time": "2025-03-08T07:20:52.149868Z"
    }
   },
   "outputs": [],
   "source": [
    "fold_lbl_distrb = pd.DataFrame(index=folds, columns=cls_idx)\n",
    "\n",
    "for n, (train_indices, val_indices) in enumerate(kfolds, start=1):\n",
    "    train_totals = labels_df.iloc[train_indices].sum()\n",
    "    val_totals = labels_df.iloc[val_indices].sum()\n",
    "\n",
    "    # To avoid division by zero, we add a small value (1E-7) to the denominator\n",
    "    ratio = val_totals / (train_totals + 1e-7)\n",
    "    fold_lbl_distrb.loc[f\"split_{n}\"] = ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6700ff5fde2f090",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T07:20:52.274867Z",
     "start_time": "2025-03-08T07:20:52.165871Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "supported_extensions = [\".jpg\", \".jpeg\", \".png\"]\n",
    "\n",
    "# Initialize an empty list to store image file paths\n",
    "images = []\n",
    "\n",
    "# Loop through supported extensions and gather image files\n",
    "for ext in supported_extensions:\n",
    "    images.extend(sorted((dataset_path / \"images\").rglob(f\"*{ext}\")))\n",
    "\n",
    "# Create the necessary directories and dataset YAML files (unchanged)\n",
    "save_path = Path(dataset_path / f\"{datetime.date.today().isoformat()}_{ksplit}-Fold_Cross-val\")\n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "ds_yamls = []\n",
    "\n",
    "for split in folds_df.columns:\n",
    "    # Create directories\n",
    "    split_dir = save_path / split\n",
    "    split_dir.mkdir(parents=True, exist_ok=True)\n",
    "    (split_dir / \"train\" / \"images\").mkdir(parents=True, exist_ok=True)\n",
    "    (split_dir / \"train\" / \"labels\").mkdir(parents=True, exist_ok=True)\n",
    "    (split_dir / \"val\" / \"images\").mkdir(parents=True, exist_ok=True)\n",
    "    (split_dir / \"val\" / \"labels\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Create dataset YAML files\n",
    "    dataset_yaml = split_dir / f\"{split}_dataset.yaml\"\n",
    "    ds_yamls.append(dataset_yaml)\n",
    "\n",
    "    with open(dataset_yaml, \"w\") as ds_y:\n",
    "        yaml.safe_dump(\n",
    "            {\n",
    "                \"path\": split_dir.as_posix(),\n",
    "                \"train\": \"train\",\n",
    "                \"val\": \"val\",\n",
    "                \"names\": classes,\n",
    "            },\n",
    "            ds_y,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f210230b1733e31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T07:20:56.634019Z",
     "start_time": "2025-03-08T07:20:52.275867Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for image, label in zip(images, labels):\n",
    "    for split, k_split in folds_df.loc[image.stem].items():\n",
    "        # Destination directory\n",
    "        img_to_path = save_path / split / k_split / \"images\"\n",
    "        lbl_to_path = save_path / split / k_split / \"labels\"\n",
    "\n",
    "        # Copy image and label files to new directory (SamefileError if file already exists)\n",
    "        shutil.copy(image, img_to_path / image.name)\n",
    "        shutil.copy(label, lbl_to_path / label.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b83e6101b0bc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_df.to_csv(save_path / \"kfold_datasplit.csv\")\n",
    "fold_lbl_distrb.to_csv(save_path / \"kfold_label_distribution.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844c4f3ffbb187e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T18:40:14.536238Z",
     "start_time": "2025-03-08T18:40:13.031779Z"
    }
   },
   "outputs": [],
   "source": [
    "from ultralytics.data.utils import autosplit\n",
    "\n",
    "autosplit(\n",
    "    path=\"paper cup.v5i.yolov8/train/images\",\n",
    "    weights=(1, 0, 0.0),\n",
    "    annotated_only=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23190c638632b9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T07:08:18.977025Z",
     "start_time": "2025-03-08T07:07:53.398607Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import imagehash\n",
    "from PIL import Image\n",
    "\n",
    "# Set folder path\n",
    "folder_path = \"paper cup.v5i.yolov8/train/images\"\n",
    "hash_size = 8  # Hash size (higher value increases accuracy but reduces speed)\n",
    "similarity_threshold = 5  # Lower means stricter matching\n",
    "\n",
    "# Dictionary to store image hashes\n",
    "hash_dict = {}\n",
    "\n",
    "def get_image_hash(image_path):\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            return imagehash.average_hash(img, hash_size=hash_size)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Process images\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "    if os.path.isfile(file_path) and filename.lower().endswith(('png', 'jpg', 'jpeg', 'bmp', 'gif')):\n",
    "        img_hash = get_image_hash(file_path)\n",
    "        \n",
    "        if img_hash:\n",
    "            # Check if similar image exists\n",
    "            for stored_hash, stored_path in hash_dict.items():\n",
    "                if img_hash - stored_hash < similarity_threshold:  # Hamming distance check\n",
    "                    print(f\"Deleting duplicate: {file_path} (similar to {stored_path})\")\n",
    "                    os.remove(file_path)\n",
    "                    break\n",
    "            else:\n",
    "                hash_dict[img_hash] = file_path  # Store new hash if not similar\n",
    "\n",
    "print(\"Duplicate removal complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcb8d4ee8711947",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T07:14:00.253852Z",
     "start_time": "2025-03-08T07:13:58.938554Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set folder paths\n",
    "jpg_folder = \"paper cup.v5i.yolov8/train/images\"  # Folder containing .jpg images\n",
    "txt_folder = \"paper cup.v5i.yolov8/train/labels\"  # Folder containing .txt files\n",
    "\n",
    "# Get all jpg filenames (without extensions)\n",
    "jpg_files = {os.path.splitext(f)[0] for f in os.listdir(jpg_folder) if f.lower().endswith('.jpg')}\n",
    "\n",
    "# Process text files\n",
    "for txt_file in os.listdir(txt_folder):\n",
    "    if txt_file.endswith('.txt'):\n",
    "        txt_name = os.path.splitext(txt_file)[0]  # Remove .txt extension\n",
    "        \n",
    "        # If no matching jpg exists, delete txt file\n",
    "        txt_path = os.path.join(txt_folder, txt_file)\n",
    "        if txt_name not in jpg_files:\n",
    "            print(f\"Deleting: {txt_path}\")\n",
    "            os.remove(txt_path)\n",
    "\n",
    "print(\"Cleanup complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eec0908d01c2482",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
