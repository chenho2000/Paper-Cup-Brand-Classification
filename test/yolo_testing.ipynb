{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9475465ed46e569",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T17:34:07.272759Z",
     "start_time": "2025-04-14T17:33:58.818789Z"
    }
   },
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import fiftyone.utils.ultralytics as fou\n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ca39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"best0.pt\")\n",
    "# Define the names of your classes\n",
    "class_names = ['cup', 'timmies']  # Replace with appropriate class names\n",
    "class_colors = ['red', 'blue'] \n",
    "\n",
    "def predict_and_save(image_path, model, output_dir):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    results = model.predict(source=image, save=False)  # Make prediction\n",
    "\n",
    "    # Convert OpenCV image (BGR) to matplotlib image (RGB)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Plot the image\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(image_rgb)\n",
    "\n",
    "    # Draw bounding boxes with labels\n",
    "    for box in results[0].boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy.tolist()[0]\n",
    "        class_id = int(box.cls[0])\n",
    "        score = box.conf[0]\n",
    "        class_label = f'{class_names[class_id]} {score:.2f}'\n",
    "\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "        rect = patches.Rectangle((x1, y1), width, height, linewidth=2, edgecolor=class_colors[class_id], facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Add class label\n",
    "        ax.text(x1, y1, class_label, color='white', fontsize=8, bbox=dict(facecolor='red', alpha=0.5))\n",
    "\n",
    "    # Save the image with bounding boxes and labels\n",
    "    output_path = os.path.join(output_dir, os.path.basename(image_path))\n",
    "    plt.axis('off')\n",
    "    plt.savefig(output_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def process_images_in_folder(folder_path, model, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for image_name in os.listdir(folder_path):\n",
    "        if image_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_path = os.path.join(folder_path, image_name)\n",
    "            predict_and_save(image_path, model, output_folder)\n",
    "\n",
    "# Define your image folder and output folder\n",
    "image_folder = \"./dataset/images/val\"\n",
    "output_folder = 'output0'\n",
    "\n",
    "# Process and save images\n",
    "process_images_in_folder(image_folder, model, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6665d09b46eebd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in fo.list_datasets():\n",
    "#     dataset = fo.load_dataset(i)\n",
    "#     dataset.delete()\n",
    "    \n",
    "# # A name for the dataset\n",
    "# name = \"QA\"\n",
    "\n",
    "# # The directory containing the dataset to import\n",
    "# dataset_dir = \"dataset\"\n",
    "\n",
    "# # The type of the dataset being imported\n",
    "# dataset_type = fo.types.YOLOv5Dataset\n",
    "\n",
    "# dataset = fo.Dataset.from_dir(\n",
    "#     dataset_dir=dataset_dir,\n",
    "#     dataset_type=dataset_type,\n",
    "#     name=name,\n",
    "#     split=\"val\")\n",
    "\n",
    "# dataset.apply_model(model, label_field=\"boxes\")\n",
    "\n",
    "# session = fo.launch_app(dataset, port=5151)\n",
    "# session.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84600291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best0.pt\n",
      "Ultralytics 8.3.85  Python-3.12.9 torch-2.6.0+cu126 CUDA:0 (NVIDIA RTX A6000, 49140MiB)\n",
      "YOLO11m summary (fused): 125 layers, 20,031,574 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\student01\\Desktop\\test\\dataset\\labels\\val.cache... 123 images, 44 backgrounds, 0 corrupt: 100%|██████████| 123/123 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:04<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        125      0.892       0.73      0.813      0.648\n",
      "                   Cup         15         29      0.952       0.69      0.826      0.693\n",
      "               Timmies         65         96      0.831      0.771        0.8      0.604\n",
      "Speed: 3.0ms preprocess, 4.2ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val\u001b[0m\n",
      "\n",
      "\n",
      "best_l.pt\n",
      "Ultralytics 8.3.85  Python-3.12.9 torch-2.6.0+cu126 CUDA:0 (NVIDIA RTX A6000, 49140MiB)\n",
      "YOLO11l summary (fused): 190 layers, 25,280,854 parameters, 0 gradients, 86.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\student01\\Desktop\\test\\dataset\\labels\\val.cache... 123 images, 44 backgrounds, 0 corrupt: 100%|██████████| 123/123 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:04<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        125      0.885      0.855      0.901      0.723\n",
      "                   Cup         15         29      0.838      0.793      0.857      0.712\n",
      "               Timmies         65         96      0.932      0.917      0.945      0.735\n",
      "Speed: 0.5ms preprocess, 7.3ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val2\u001b[0m\n",
      "\n",
      "\n",
      "best_m.pt\n",
      "Ultralytics 8.3.85  Python-3.12.9 torch-2.6.0+cu126 CUDA:0 (NVIDIA RTX A6000, 49140MiB)\n",
      "YOLO11m summary (fused): 125 layers, 20,031,574 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\student01\\Desktop\\test\\dataset\\labels\\val.cache... 123 images, 44 backgrounds, 0 corrupt: 100%|██████████| 123/123 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:04<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        125      0.903      0.883      0.896      0.728\n",
      "                   Cup         15         29      0.923      0.828      0.886      0.749\n",
      "               Timmies         65         96      0.884      0.938      0.906      0.706\n",
      "Speed: 0.4ms preprocess, 5.8ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val3\u001b[0m\n",
      "\n",
      "\n",
      "l_550.pt\n",
      "Ultralytics 8.3.85  Python-3.12.9 torch-2.6.0+cu126 CUDA:0 (NVIDIA RTX A6000, 49140MiB)\n",
      "YOLO11l summary (fused): 190 layers, 25,280,854 parameters, 0 gradients, 86.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\student01\\Desktop\\test\\dataset\\labels\\val.cache... 123 images, 44 backgrounds, 0 corrupt: 100%|██████████| 123/123 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:04<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        125      0.883      0.888      0.913       0.73\n",
      "                   Cup         15         29      0.828      0.828      0.869      0.717\n",
      "               Timmies         65         96      0.938      0.948      0.957      0.743\n",
      "Speed: 0.4ms preprocess, 8.0ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val4\u001b[0m\n",
      "\n",
      "\n",
      "m_550.pt\n",
      "Ultralytics 8.3.85  Python-3.12.9 torch-2.6.0+cu126 CUDA:0 (NVIDIA RTX A6000, 49140MiB)\n",
      "YOLO11m summary (fused): 125 layers, 20,031,574 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\student01\\Desktop\\test\\dataset\\labels\\val.cache... 123 images, 44 backgrounds, 0 corrupt: 100%|██████████| 123/123 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:04<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        123        125      0.901      0.888      0.895      0.723\n",
      "                   Cup         15         29      0.923      0.828      0.887      0.744\n",
      "               Timmies         65         96      0.879      0.948      0.903      0.703\n",
      "Speed: 0.4ms preprocess, 6.5ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val5\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "directory = '.'\n",
    "\n",
    "for root, _, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith('.pt'):\n",
    "            print(file)\n",
    "            model = YOLO(file)\n",
    "            validation_results = model.val(data=\"dataset/dataset.yaml\", conf=0.5)\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5140616eda6c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SYDE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
